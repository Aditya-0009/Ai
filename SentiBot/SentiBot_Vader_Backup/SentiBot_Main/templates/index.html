<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SentiBot</title>
    <link rel="stylesheet" href="static/index.css"> <!-- Corrected CSS file path -->
</head>
<body>
    <h1 id="senti-bot-title" class="header-title">SentiBot-AudioAnalysis</h1>

    <div class="container">
        <!-- Left Section: Conversations -->
        <div class="left-section">
            <div class="conversations"></div>
        </div>
        
        <!-- Right Section: Video Stream and Manual Text Input -->
        <div class="right-section">
            <!-- Video Stream -->
            <div class="video-container" id="videoContainer">
                <video id="videoElement" autoplay muted style="display: none;"></video>
                <!-- Embedded GIF -->
                <div id="gifContainer"> <!-- Remove inline style to display GIF container by default -->
                    <img src="static/user_camera.gif" alt="GIF">
                </div>
            </div>

            <!-- Start/Stop Button -->
            <div class="record-buttons">
                <button id="recordButton" onclick="startRecording()">Start Recording</button>
                <button id="stopButton" style="display:none;" onclick="stopRecording()">Stop Recording</button>
            </div>

            <!-- Manual Text Input -->
            <div class="manual-text-input">
                <hr class="separator-line"> <!-- Separator line -->
                <textarea id="textInput" placeholder="Type your text here..." rows="4" cols="30"></textarea>
            </div>

            <!-- Process Text Button -->
            <div class="process-text-button">
                <button id="processButton" onclick="processText()">Process Text</button>
            </div>
        </div>
    </div>
    
    <script>
        let recognition;
        let isRecording = false;
        let conversationCount = 0;

        window.onload = function() {
            // Show the GIF container and hide the video element when the page loads
            document.getElementById('videoElement').style.display = 'none';
            document.getElementById('gifContainer').style.display = 'block';
        };

        function startRecording() {
            if (isRecording) return;
            isRecording = true;

            const recordButton = document.getElementById('recordButton');
            const stopButton = document.getElementById('stopButton');
            recordButton.style.display = 'none';
            stopButton.style.display = 'inline-block';

            // Show the video stream and hide the GIF
            document.getElementById('videoElement').style.display = 'block';
            document.getElementById('gifContainer').style.display = 'none';

            conversationCount++; // Increment conversation count

            const conversationsDiv = document.querySelector('.conversations');
            const newConversation = document.createElement('div'); // Create new conversation box
            newConversation.classList.add('conversation-box');
            newConversation.innerHTML = `<div class="conversation-header">Conversation${conversationCount}</div><div class="conversation-content"></div>`;
            conversationsDiv.appendChild(newConversation); // Append conversation box

            const newContent = document.createElement('div'); // Create new content cell inside conversation box
            newContent.classList.add('conversation-text');
            newConversation.querySelector('.conversation-content').appendChild(newContent);

            navigator.mediaDevices.getUserMedia({ video: true, audio: true })
                .then(function(stream) {
                    const videoElement = document.getElementById('videoElement');
                    videoElement.srcObject = stream;

                    stream.getAudioTracks().forEach(track => {
                        track.enabled = false;
                    });

                    recognition = new webkitSpeechRecognition();
                    recognition.continuous = true;
                    recognition.interimResults = true;

                    recognition.onresult = function(event) {
                        const transcript = Array.from(event.results)
                            .map(result => result[0])
                            .map(result => result.transcript)
                            .join(' ');

                        newContent.textContent = transcript;

                        if (newContent.textContent.length > 5000) {
                            newContent.textContent = newContent.textContent.substring(newContent.textContent.length - 5000);
                        }
                    };

                    recognition.start();
                })
                .catch(function(err) {
                    console.error('Error accessing video stream:', err);
                });
        }

        function stopRecording() {
            const recordButton = document.getElementById('recordButton');
            const stopButton = document.getElementById('stopButton');
            stopButton.disabled = true;
            
            setTimeout(() => {
                stopButton.disabled = false;
            }, 1000);

            if (!isRecording) return;
            isRecording = false;

            recordButton.style.display = 'inline-block';
            stopButton.style.display = 'none';

            // Stop the speech recognition
            recognition.stop();

            // Stop the video stream and show the GIF
            const videoContainer = document.getElementById('videoContainer');
            const videoElement = document.getElementById('videoElement');
            const gifContainer = document.getElementById('gifContainer');
            
            videoElement.style.display = 'none';
            gifContainer.style.display = 'block';

            const stream = videoElement.srcObject;
            const tracks = stream.getTracks();
            tracks.forEach(track => track.stop());

            // Perform sentiment analysis prediction and display predicted mood
            const conversationText = document.querySelector('.conversation-box:last-child .conversation-text').textContent;

            if (!conversationText.trim()) {
                alert('Enter your input to get Sentiment Prediction.');
                return; // Exit the function if there's no input
            }

            fetch('/process_audio_video', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    text_data: conversationText
                })
            })
            .then(response => response.json())
            .then(data => {
                if (data.status === 'success') {
                    const predictedMood = data.predicted_mood;
                    const conversationsDiv = document.querySelector('.conversations');
                    const newMood = document.createElement('div');
                    newMood.classList.add('predicted-mood');
                    newMood.innerHTML = `<hr><p>Predicted Mood: ${predictedMood}</p>`;
                    const lastConversation = conversationsDiv.lastChild;
                    lastConversation.querySelector('.conversation-content').appendChild(newMood);
                }
            })
            .catch(error => {
                console.error('Error processing text:', error);
            });
        }

        function processText() {
        const textInput = document.getElementById('textInput').value;

        if (!textInput.trim()) {
            alert('Enter your input to get Sentiment Prediction.');
            return; // Exit the function if there's no input
        }
        const conversationsDiv = document.querySelector('.conversations');

            const newConversation = document.createElement('div'); // Create new conversation box
            newConversation.classList.add('conversation-box');
            newConversation.innerHTML = `<div class="conversation-header">Conversation${++conversationCount}</div><div class="conversation-content"><div class="conversation-text">${textInput}</div></div>`;
            conversationsDiv.appendChild(newConversation); // Append conversation box

            stopRecording(); // Stop recording if ongoing

            // Clear the text input field
            document.getElementById('textInput').value = '';

            // Perform sentiment analysis prediction and display predicted mood
            fetch('/process_audio_video', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    text_data: textInput
                })
            })
            .then(response => response.json())
            .then(data => {
                if (data.status === 'success') {
                    const predictedMood = data.predicted_mood;
                    const newMood = document.createElement('div');
                    newMood.classList.add('predicted-mood');
                    newMood.innerHTML = `<hr><p>Predicted Mood: ${predictedMood}</p>`;
                    const lastConversation = conversationsDiv.lastChild;
                    lastConversation.querySelector('.conversation-content').appendChild(newMood);
                }
            })
            .catch(error => {
                console.error('Error processing text:', error);
            });
        }

    </script>
</body>
</html>
